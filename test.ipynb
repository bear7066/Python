{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "device = 'CUDA' if torch.cuda.is_available() else 'CPU'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LLM_LeaderBoard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods of using torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 11,  12,  23,  98, -14])\n",
      "tensor([[1, 2],\n",
      "        [5, 6],\n",
      "        [7, 9],\n",
      "        [0, 2]])\n",
      "tensor([[1, 2],\n",
      "        [5, 6],\n",
      "        [7, 9],\n",
      "        [0, 2]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randint = torch.randint(-100, 100,(5,))\n",
    "#print(randint)\n",
    "tensor = torch.tensor([[1, 2], [5, 6], [7, 9], [0, 2]])\n",
    "#print(tensor)\n",
    "zeros = torch.zeros(3, 4)\n",
    "#print(tensor)\n",
    "ones = torch.ones(3, 4)\n",
    "#print(ones)\n",
    "input = torch.empty(3, 4)\n",
    "#print(input)\n",
    "arrange = torch.arange(5)\n",
    "#print(arrange)\n",
    "linspace = torch.linspace(3, 10, steps=5)\n",
    "logspace = torch.logspace(start = -10, end = 10 , steps=5)\n",
    "linspace #logspace \n",
    "\n",
    "eye = torch.eye(5)\n",
    "a = torch.empty((2, 3), dtype=torch.int64)\n",
    "empty_like = torch.empty_like(a)\n",
    "empty_like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the performance \n",
    "#### Which we can see GPU is faster than CPU when the data is big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0003900528\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "zeros = torch.zeros(2,2)\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '—', '‘', '’', '“', '”', '•', '™']\n",
      "\n",
      "\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "with open('wizard_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "chars = sorted(set(text))\n",
    "print(chars)\n",
    "print(\"\\n\")\n",
    "print(len(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([48, 65, 62,  1, 44, 75, 72, 67, 62, 60, 77,  1, 35, 78, 77, 62, 71, 59,\n",
      "        62, 75, 64,  1, 62, 30, 72, 72, 68,  1, 72, 63,  1, 32, 72, 75, 72, 77,\n",
      "        65, 82,  1, 58, 71, 61,  1, 77, 65, 62,  1, 51, 66, 83, 58, 75, 61,  1,\n",
      "        66, 71,  1, 43, 83,  0,  1,  1,  1,  1,  0, 48, 65, 66, 76,  1, 62, 59,\n",
      "        72, 72, 68,  1, 66, 76,  1, 63, 72, 75,  1, 77, 65, 62,  1, 78, 76, 62,\n",
      "         1, 72, 63,  1, 58, 71, 82, 72, 71, 62])\n"
     ]
    }
   ],
   "source": [
    "# {'a':0, 'b':1....}\n",
    "string_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "# {'1': a, '2': b....}\n",
    "int_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "#kk = encode('hellosdfoijtw;a')\n",
    "#decode(kk)\n",
    "\n",
    "# array, which support GPU Acceralation\n",
    "data = torch.tensor(encode(text), dtype = torch.long)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Corpus (語料庫)\n",
    "#### Spilt data by 80%, 20% to make sure the data are unique ?\n",
    "#### What is Bigram Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "valid_data = data[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([48]) ,target is:  tensor(65)\n",
      "When input is tensor([48, 65]) ,target is:  tensor(62)\n",
      "When input is tensor([48, 65, 62]) ,target is:  tensor(1)\n",
      "When input is tensor([48, 65, 62,  1]) ,target is:  tensor(44)\n",
      "When input is tensor([48, 65, 62,  1, 44]) ,target is:  tensor(75)\n",
      "When input is tensor([48, 65, 62,  1, 44, 75]) ,target is:  tensor(72)\n",
      "When input is tensor([48, 65, 62,  1, 44, 75, 72]) ,target is:  tensor(67)\n",
      "When input is tensor([48, 65, 62,  1, 44, 75, 72, 67]) ,target is:  tensor(62)\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for i in range(block_size):\n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print('When input is', context, ',target is: ', target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# randomly generate stuff between 0.1 => 0, and 0.9 => 1\n",
    "p = torch.tensor([0.1, 0.9])\n",
    "sample = torch.multinomial(p, num_samples=3, replacement=True)\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate\n",
    "tensor = torch.tensor([1, 2, 3, 4])\n",
    "out = torch.cat((tensor, torch.tensor([9])), dim=0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.tril(torch.ones(5, 5))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.triu(torch.ones(5, 5))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.zeros(5, 5).masked_fill(torch.tril(torch.ones(5, 5)) == 0, float('-inf'))\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exponential \n",
    "torch.exp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize a matrix with zeros\n",
    "input = torch.zeros(2, 3, 4)\n",
    "print(input.shape)\n",
    "# swap the element 0 and 2\n",
    "out = input.transpose(0, 2)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# stack tensor together\n",
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "tensor3 = torch.tensor([7, 8, 9])\n",
    "stacked_tensor = torch.stack([tensor1, tensor2, tensor3])\n",
    "print(stacked_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch NN(Trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Torch_NN Document](https://pytorch.org/docs/stable/nn.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.4503,  1.6298, -3.6123], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "sample = torch.tensor([10., 10., 10.])\n",
    "linear = nn.Linear(3, 3, bias = False)\n",
    "print(linear(sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax function: probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as f\n",
    "tensor1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "softmax_output = f.softmax(tensor1, dim=0)\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4996e+00, -6.6733e-01, -4.2005e-03, -6.2238e-01, -1.3870e+00,\n",
      "          8.4411e-01,  4.6126e-01, -6.0413e-01,  2.3426e+00, -1.4980e+00,\n",
      "         -1.1938e+00,  5.1646e-01,  4.7292e-01,  6.5138e-01,  1.1003e+00,\n",
      "          3.9714e-01, -9.1082e-01, -7.4354e-01, -3.5110e-01,  3.3945e-01,\n",
      "          8.5000e-01,  1.4677e-01,  9.9064e-01,  4.8180e-01,  1.4357e+00,\n",
      "         -6.6440e-01,  8.2177e-01,  4.4125e-01, -1.2090e+00, -8.0341e-01,\n",
      "          2.4029e+00, -1.0162e+00,  3.5460e-02,  2.6622e-01,  5.0750e-01,\n",
      "         -4.5776e-01,  1.3804e+00, -3.7393e-01, -3.4509e-01,  5.2088e-01,\n",
      "          4.2730e-01, -1.1087e+00,  1.1989e-02,  1.1203e+00,  1.7891e+00,\n",
      "          7.9121e-01,  7.4537e-01,  5.9577e-01,  2.4072e-01, -1.4452e-01,\n",
      "          9.3456e-01, -5.2609e-01, -7.6928e-01,  1.5356e+00,  1.5098e-01,\n",
      "          7.1828e-01, -1.3994e-02,  4.4674e-01,  2.3815e+00, -6.5477e-01,\n",
      "         -5.5225e-01,  4.8211e-01, -1.0292e+00,  2.8332e+00, -9.4680e-01,\n",
      "         -6.2137e-01,  1.2247e+00, -1.1668e-02, -1.7517e-01, -3.6255e-01,\n",
      "          1.2866e+00, -2.5040e-01, -1.1861e+00, -2.5319e-01,  4.9196e-01,\n",
      "          1.5955e+00, -4.1970e-01, -7.0197e-01,  4.9172e-01,  2.2441e+00,\n",
      "          2.3616e-01, -9.3892e-01, -4.7538e-01, -8.4220e-01, -1.3265e+00,\n",
      "         -2.1867e+00,  3.5477e-01, -5.7798e-01, -1.1938e+00,  7.4972e-01,\n",
      "         -4.7288e-01, -7.6886e-01,  7.1450e-01,  2.2581e+00,  4.4006e-01,\n",
      "          2.7481e-01,  7.1276e-01,  7.7808e-01, -8.7579e-01,  9.7384e-01],\n",
      "        [-1.3298e+00, -3.4471e-01, -2.4192e-01,  8.9388e-01, -1.6086e-01,\n",
      "         -7.4062e-02, -4.8946e-01, -8.1900e-01,  1.1574e-01, -2.2328e+00,\n",
      "          1.3311e+00, -6.4484e-01,  1.6355e+00,  1.6430e+00, -2.8195e-01,\n",
      "          2.8409e-01,  1.1582e+00,  7.4133e-02, -7.2074e-01, -1.4003e-01,\n",
      "          2.7301e+00,  2.6965e-02,  5.9534e-02,  5.5750e-01,  3.2380e-02,\n",
      "         -3.5453e-01, -2.0992e-01,  1.1144e+00,  1.1287e+00, -6.8121e-01,\n",
      "          2.9521e-01, -8.0776e-01,  1.9878e+00,  1.2990e+00, -5.5982e-01,\n",
      "         -1.2599e+00, -1.7090e+00,  2.0356e+00,  7.7847e-01, -1.9402e+00,\n",
      "          1.0820e+00, -2.8783e-01, -2.7728e+00, -4.8583e-01,  2.3304e+00,\n",
      "         -5.0448e-01,  2.2748e+00, -2.0586e+00, -4.7887e-02, -1.8403e+00,\n",
      "          1.2697e+00,  1.3417e+00, -4.8966e-02, -1.7848e+00, -3.4210e-02,\n",
      "          1.5767e-01,  2.2577e-01,  3.3716e+00,  2.4709e-01,  2.8691e-01,\n",
      "          3.4841e-01, -8.6526e-02, -2.3633e-01, -6.1463e-01,  7.7983e-02,\n",
      "          1.4574e+00,  9.9603e-02, -7.2398e-01,  2.1232e+00,  8.0555e-02,\n",
      "          3.4945e-01, -3.3630e-01,  8.3865e-01, -1.2730e+00,  1.5341e-01,\n",
      "          2.6351e-02,  4.3047e-01,  5.5409e-01,  6.3172e-01, -1.3248e+00,\n",
      "         -9.7895e-01,  5.9470e-01,  5.0104e-01,  1.4957e+00, -9.0567e-01,\n",
      "          1.1886e+00, -1.0806e+00, -1.5778e-01, -4.3733e-01, -1.2413e+00,\n",
      "          2.2979e-01, -8.7808e-03,  3.5123e-02,  9.0455e-02,  5.0929e-01,\n",
      "          2.1303e-01,  2.3623e-01,  1.0053e+00, -5.9578e-01, -1.1152e+00],\n",
      "        [ 3.7172e-01, -4.2661e-01, -1.8105e-01,  1.3023e+00,  1.3607e-01,\n",
      "         -1.4195e+00, -9.1731e-01,  1.8313e+00, -5.7404e-01, -2.3509e+00,\n",
      "         -7.3349e-01, -4.3993e-01, -6.7551e-01,  2.5757e-01,  9.9275e-01,\n",
      "         -7.9521e-04,  1.5558e+00,  3.6329e-01,  1.0302e+00,  2.2820e+00,\n",
      "         -5.9559e-01, -1.6725e-01,  9.6707e-02, -2.6093e-01,  1.2206e-01,\n",
      "         -1.2590e+00, -1.1875e+00,  2.4560e+00, -5.4953e-03,  1.7878e+00,\n",
      "          2.7010e-01,  9.5814e-01,  1.0264e+00,  1.4888e+00, -7.9762e-01,\n",
      "          3.6292e-01,  4.1054e-01,  4.5319e-01,  1.8869e-01, -1.7342e-01,\n",
      "         -4.9492e-01, -6.0782e-01,  2.1490e-01,  1.0472e+00,  1.1661e+00,\n",
      "          4.6365e-01,  1.1979e+00, -8.0220e-01, -7.0412e-01,  9.0235e-02,\n",
      "          8.6095e-01,  1.0671e-01,  4.9818e-01,  3.8338e-01,  4.1186e-01,\n",
      "          1.2451e+00,  7.9158e-01,  1.5275e-02, -5.0876e-01, -8.2989e-02,\n",
      "         -9.1253e-01, -1.1509e+00, -1.6118e+00,  1.4010e+00, -8.3252e-01,\n",
      "          1.4005e+00,  8.1114e-01, -9.3063e-01, -7.4028e-01,  9.5892e-01,\n",
      "          2.8664e-01, -1.3699e+00,  1.4006e+00, -9.1628e-01, -1.4000e+00,\n",
      "          1.6484e+00, -1.1395e+00,  1.7047e-01,  3.9818e-01,  8.6867e-02,\n",
      "          2.3495e-01,  1.0328e+00, -1.8155e+00,  1.3848e+00, -7.6964e-01,\n",
      "         -5.7677e-01, -1.3722e+00,  7.0583e-01,  2.7763e+00,  1.9789e+00,\n",
      "         -1.3060e+00,  1.3076e+00, -1.9465e-01,  1.6835e+00,  1.1677e-01,\n",
      "         -5.0563e-01,  2.0579e-01,  1.1161e+00,  1.5354e+00, -3.2119e-01],\n",
      "        [ 8.8798e-01,  3.2046e-01, -1.0009e+00,  1.2830e+00, -2.2895e-01,\n",
      "          1.4115e+00, -7.2256e-01, -5.6030e-01, -3.8376e-01, -8.0541e-01,\n",
      "         -3.9879e-01, -8.2140e-01,  9.0056e-01,  2.0756e+00, -5.9893e-01,\n",
      "         -1.2059e+00,  6.5842e-01,  4.6454e-01, -4.9913e-01, -3.6062e-01,\n",
      "         -2.9525e-01, -4.4219e-02,  6.9688e-01, -3.2754e-01, -1.3089e+00,\n",
      "         -7.6614e-01,  3.1054e-01, -2.9421e-01,  7.5657e-01, -1.7301e+00,\n",
      "          2.0401e-01,  2.0065e-01, -6.8585e-01, -6.3436e-01, -6.9783e-01,\n",
      "          4.9879e-01, -1.0484e+00,  2.6771e-02, -4.9598e-01, -9.9791e-01,\n",
      "          4.7979e-01, -3.2566e-01,  9.7281e-01, -9.9147e-01, -1.5160e+00,\n",
      "          4.1111e-01, -9.3012e-02,  1.2838e+00,  9.0777e-01, -1.1288e+00,\n",
      "         -7.4663e-01, -1.5756e-01,  7.9630e-01,  1.0952e+00, -1.4988e-01,\n",
      "          1.2020e+00, -1.4533e-02,  5.8448e-02,  6.3601e-01,  1.4431e+00,\n",
      "          9.1455e-01,  2.2290e-01,  8.6326e-01,  9.4383e-01, -6.9742e-01,\n",
      "          2.2706e+00,  6.7708e-01,  1.6621e+00, -7.2723e-01,  2.0436e-01,\n",
      "          2.6649e-02, -4.6769e-01, -4.3954e-01, -5.5887e-01,  3.1266e+00,\n",
      "         -9.5115e-01, -3.7761e-01,  3.6448e-01, -5.6240e-01, -1.1925e+00,\n",
      "         -3.9876e-01,  9.5477e-01, -9.4457e-01,  2.9797e-01, -3.3043e-01,\n",
      "         -1.3381e-01, -2.7023e-03, -5.2277e-01, -1.1941e+00,  4.8324e-01,\n",
      "          1.4363e-01, -1.5146e-01,  1.1295e+00, -2.6343e-02, -6.9417e-01,\n",
      "          5.1411e-02,  2.8015e-01, -1.0420e+00,  8.4839e-01, -4.7530e-01]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# initialize embedding layer\n",
    "vocab_size = 1000\n",
    "embedded_dim = 100\n",
    "embedding = nn.Embedding(vocab_size, embedded_dim)\n",
    "\n",
    "input_indices = torch.LongTensor([1, 5, 3, 2])\n",
    "\n",
    "embedded_output = embedding(input_indices)\n",
    "print(embedded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
